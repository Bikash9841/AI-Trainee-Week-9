# Transformer for Language Translation

## Task Performed:

1. Build the encoder-decoder architecture based on `Attention is All You Need` paper.
2. Use `CohleM/english-to-nepali` Dataset from the HuggingFace.
3. Made the Custom trained Tokenizer separately for English and Nepali Language.
4. Train the model and perform inference on English to Nepali Translation.
